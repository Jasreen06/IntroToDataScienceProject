---
title: 'DATS6101 Project 2: Exploring Hotel Booking Cancellations'
author: "Group 6 : Jasreen Kaur Mehta, Pranav Dhawan, Tycho Gormley"
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r init, include=FALSE}
#Import required libraries
library(ezids)
library(ggplot2)
library(dplyr)
library(caret)
library(tidyverse)
library(pROC)
library(corrplot)
library(randomForest)
library(rpart)
library(glmnet)


#Setup knitter options
knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3)
```

# **Part 1 Recap**

In our Part 1, we analyzed a hotel booking dataset from the INN Hotels Group to understand the factors influencing booking cancellations.\

```{r import_dataset}
hotel_data <- read.csv("../../Dataset/INNHotelsGroup_min.csv")
``` 

```{r data_structure}
str(hotel_data)
```
The dataset contains hotel bookings collected from 2017-2018 and is characterized by a total of 19 columns, comprising 5 categorical and 14 numerical variables.\

```{r bar_plot1}
print(ggplot(hotel_data, aes(x = booking_status)) +
  geom_bar(fill = "lightblue") +
  labs(title = "Booking Status Distribution", x = "Booking Status", y = "Count"))
```

The dataset contains 36,275 bookings. Of the total bookings, 24,390 bookings were not canceled (67.2%), while 11,885 bookings were canceled (32.8%), reflecting a significant cancellation rate that offers rich insights into factors influencing booking decisions.

## **Key Statistical Findings**

**1. Special Requests and Cancellations:** \
Bookings with special requests had a significantly lower cancellation rate (20.2%) compared to those without (43.2%).\ 
Chi-square test revealed a statistically significant association between special requests and booking status.\

**2. Previous Cancellation History:**\
Surprisingly, guests with previous cancellations had a much lower current cancellation rate (4.73%) compared to those without (33.03%).\
This suggests that past cancellation history might not be a straightforward predictor of future booking behavior.\

**3. Factors Influencing Cancellations:**\
**3.1 Lead Time:**\

1. Average lead time for canceled bookings: 139.2 days\
2. Average lead time for non-canceled bookings: 58.9 days\
3. Longer lead times strongly correlated with higher cancellation probability.\

**3.2 Room Price:**\

1. Canceled bookings had a higher average room price.\
2. Price difference: Approximately 10.7 units higher for canceled bookings.\

**4. Seasonal Variations:**\
The correlation between factors and cancellations varied across seasons:\

**4.1 Fall:**\
Strongest lead time correlation (0.54).\

**4.2 Summer:**\
Special requests most negatively correlated with cancellations (-0.30).\

**4.3 Spring:** \
Unique pattern with special requests having a strong negative correlation (-0.36).\

**4.4 Winter:** \
Slightly different dynamics with weaker correlations.\

```{r correlation, fig.width=15, fig.height=10}
hotel_data$booking_status_binary <- ifelse(hotel_data$booking_status == "Canceled", 1, 0)

remove_zero_variance <- function(df) {
  df[, sapply(df, function(col) sd(col, na.rm = TRUE) != 0)]
}

data_filtered <- remove_zero_variance(select_if(hotel_data, is.numeric))

cor_data <- cor(data_filtered, use = "complete.obs")

corrplot(cor_data, method = "color", addCoef.col = "black", 
         title = "Correlation Matrix Recap", number.cex = 1, 
         tl.cex = 0.8, mar = c(1, 1, 2, 1))
```

Lead time strongly predicts cancellations, with longer lead times increasing likelihood (0.44). More special requests (-0.25) and repeated guest status (-0.11) reduce cancellations, reflecting customer commitment and loyalty. Price per room has a weak positive correlation (0.14) with cancellations. Factors like travel party size and stay length show minimal impact on cancellation likelihood.\

## **Preliminary Conclusions:**\

**1.** Lead time emerged as the most critical factor in predicting booking cancellations.\
**2.** Special requests significantly reduce the likelihood of cancellations.\
**3.** Booking behavior varies considerably across different seasons.\
**4.** Higher-priced rooms show a slight tendency towards more cancellations.\

# **SMART Questions:** \

## **1. What key factors most strongly influence booking cancellations?**\

```{r}
hotel_data$type_of_meal_plan <- as.factor(hotel_data$type_of_meal_plan)
hotel_data$room_type_reserved <- as.factor(hotel_data$room_type_reserved)
hotel_data$market_segment_type <- as.factor(hotel_data$market_segment_type)
#hotel_data$booking_status <- as.factor(hotel_data$booking_status)


# Train a Random Forest model
rf_model1 <-randomForest(booking_status_binary ~ no_of_adults + no_of_children + no_of_weekend_nights + 
                          no_of_week_nights + type_of_meal_plan + required_car_parking_space + 
                          room_type_reserved + lead_time + arrival_year + arrival_month + 
                          market_segment_type + repeated_guest + 
                          no_of_previous_cancellations + avg_price_per_room + no_of_special_requests,
                        data = hotel_data, importance = TRUE, ntree = 100)

print(rf_model1)



# Extract feature importance
feature_importance <- importance(rf_model1)

feature_importance

# Convert feature importance to a data frame for plotting
importance_df <- data.frame(Feature = rownames(feature_importance), Importance = feature_importance[,1])

importance_df <- importance_df[order(-importance_df$Importance),]
importance_df




# Plot feature importance using ggplot2
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +  # Flip the axes to make it easier to read
  labs(title = "Feature Importance from Random Forest Model",
       x = "Feature", y = "Importance") +
  theme_minimal()

```

## **2. Can we predict the likelihood of booking cancellation based on the lead time?**\

```{r}
set.seed(123)
train_index <- createDataPartition(hotel_data$booking_status_binary, p = 0.7, list = FALSE)
train_data <- hotel_data[train_index, ]
test_data <- hotel_data[-train_index, ]
```

```{r}
logistic_model <- glm(
  booking_status_binary ~ lead_time,
  data = train_data, 
  family = binomial()
)

summary(logistic_model)
```

```{r}
test_predictions <- predict(logistic_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(test_predictions > 0.5, 1, 0)
```

```{r}
confusion_matrix <- table(Actual = test_data$booking_status_binary, 
                          Predicted = predicted_classes)
print("Confusion Matrix:")
print(confusion_matrix)
```

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
recall <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("\nModel Performance Metrics:\n")
cat("Accuracy:", round(accuracy, 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:", round(recall, 4), "\n")
cat("F1 Score:", round(f1_score, 4), "\n")
```
**1. Accuracy:** 0.754, meaning the model correctly classifies 75.4% of the bookings.\
**2. Precision:** 0.723, indicating that 72.3% of the predictions of canceled bookings are correct.\
**3. Recall:** 0.415, meaning the model correctly identifies 41.5% of the actual canceled bookings.\
**4. F1-Score:** 0.527, which is the harmonic mean of precision and recall, providing a balanced evaluation of the model's performance.\

```{r}
roc_curve <- roc(test_data$booking_status_binary, test_predictions)
plot(roc_curve, main = "ROC Curve for Booking Cancellation Prediction")
```

The plot indicates that as the specificity (the ability to correctly identify non-canceled bookings) increases, the sensitivity (the ability to correctly identify canceled bookings) also increases. This suggests that the model has good discriminative power in predicting booking cancellations.\

```{r}
auc_value <- auc(roc_curve)
cat("Area Under the ROC Curve (AUC):", round(auc_value, 4), "\n")
```
Area Under the ROC Curve (AUC): 0.75, suggesting the model has good discriminative power in predicting booking cancellations.\

```{r}
hotel_data$booking_status_binary <- as.numeric(as.character(hotel_data$booking_status_binary))

ggplot(hotel_data, aes(x = lead_time, y = booking_status_binary)) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = TRUE) +
  labs(
    title = "Probability of Booking Cancellation vs Lead Time",
    x = "Lead Time (Days)",
    y = "Probability of Cancellation"
  ) +
  theme_minimal()
```

The graph shows the relationship between the lead time (in days) and the probability of booking cancellation. As the lead time increases, the probability of booking cancellation rises in a non-linear fashion, with the curve becoming more steep at higher lead times.\

## **3. What is the relationship between room price and the likelihood of a booking being canceled or not?**

```{r}


# Load necessary libraries
library(tidyverse)

# Load the dataset (assuming the file is saved as CSV)
#data <- read.csv("../../Dataset/INNHotelsGroup_min.csv")

# Clean the data: convert booking_status to a binary variable
#data$booking_status <- ifelse(data$booking_status == "Canceled", 1, 0)


# Fit a logistic regression model
lrmodel1 <- glm(booking_status_binary ~ avg_price_per_room, data = hotel_data, family = binomial)

# Summary of the model
summary(lrmodel1)

# Predict the probabilities
hotel_data$predicted_prob <- predict(lrmodel1, type = "response")

# Create a binary prediction based on a threshold of 0.5
hotel_data$predicted_class <- ifelse(hotel_data$predicted_prob > 0.5, 1, 0)

# Model evaluation
conf_matrix <- table(hotel_data$booking_status_binary, hotel_data$predicted_class)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy, 2)))


# You can also calculate AUC-ROC if needed:
library(pROC)
roc_curve <- roc(hotel_data$booking_status_binary, hotel_data$predicted_prob)
plot(roc_curve)

# Scatter plot to examine the relationship between price and cancellation
plot(hotel_data$avg_price_per_room, hotel_data$booking_status_binary, 
     main = "Scatter plot of Avg Price per Room vs Booking Status", 
     xlab = "Average Price per Room", ylab = "Booking Status")

# Boxplot for average price per room vs booking cancellation status
boxplot(avg_price_per_room ~ booking_status_binary, data = hotel_data, 
        main = "Boxplot of Avg Price per Room vs Booking Status", 
        xlab = "Booking Status", ylab = "Average Price per Room")




auc_value <- auc(roc_curve)
print(paste("AUC:", round(auc_value, 2)))
```

## **5. Can we predict high-demand periods?**
 
```{r}
prepare_booking_data <- function(hotel_data) {
  booking_data <- hotel_data %>%
    mutate(
      high_demand = as.factor(ifelse(
        avg_price_per_room > quantile(avg_price_per_room, 0.75), 
        1, 0
      )),
      booking_month = as.factor(arrival_month),
      is_weekend = no_of_weekend_nights > 0,
      total_nights = no_of_weekend_nights + no_of_week_nights,
      is_repeated_guest = repeated_guest > 0
    )
  
  return(booking_data)
}
prepared_data <- prepare_booking_data(hotel_data)
```

```{r}
set.seed(123)
train_index <- createDataPartition(prepared_data$high_demand, p = 0.7, list = FALSE)
train_data <- prepared_data[train_index, ]
test_data <- prepared_data[-train_index, ]
```

```{r}
# Random Forest Model
rf_model <- randomForest(
  high_demand ~ lead_time + 
                no_of_adults + 
                no_of_children + 
                total_nights + 
                booking_month + 
                market_segment_type + 
                is_repeated_guest,
  data = train_data,
  ntree = 500,
  importance = TRUE
)

evaluate_model <- function(actual, predicted, model_name) {
  conf_matrix <- confusionMatrix(as.factor(predicted), as.factor(actual))
  
  results <- data.frame(
    Model = model_name,
    Accuracy = conf_matrix$overall['Accuracy'],
    Precision = conf_matrix$byClass['Precision'],
    Recall = conf_matrix$byClass['Recall'],
    F1 = conf_matrix$byClass['F1']
  )
  
  return(results)
}

rf_pred <- predict(rf_model, newdata = test_data, type = "prob")[,2]
rf_class <- ifelse(rf_pred > 0.5, 1, 0)
```

```{r}
rf_results <- evaluate_model(test_data$high_demand, rf_class, "Random Forest")
print(rf_results)
```


```{r}
rf_importance <- data.frame(
  Feature = rownames(importance(rf_model)),
  Importance = importance(rf_model)[,1]
) %>% arrange(desc(Importance))
print(head(rf_importance, 10))
```

```{r}
ggplot(head(rf_importance, 10), aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Top 10 Features Predicting High-Demand Periods",
    x = "Features",
    y = "Importance"
  ) +
  theme_minimal()
```

```{r}
predict_high_demand_periods <- function(model, test_data) {
  pred_probs <- predict(model, newdata = test_data, type = "prob")[,2]
  high_demand_periods <- test_data[pred_probs > 0.7, ]
  
  print("High-Demand Periods Prediction:")
  print(paste("Total High-Demand Periods:", sum(pred_probs > 0.7)))
  print("Sample of High-Demand Periods:")
  print(head(high_demand_periods))
  
  return(high_demand_periods)
}

high_demand_periods <- predict_high_demand_periods(rf_model, test_data)
```

## **Creating model including important features**

```{r}
# Load necessary libraries
library(car)

# Assuming you've already fitted the logistic regression model
lm_model1 <- lm(booking_status_binary ~ lead_time + no_of_special_requests + avg_price_per_room + 
                 market_segment_type + no_of_week_nights + no_of_weekend_nights + arrival_month,
                 data = hotel_data)
#summary(lm_model1)

gvif_values <- vif(lm_model1)

print(gvif_values)

# Manually extract degrees of freedom (Df) for each variable
df_values <- sapply(names(gvif_values), function(var) {
  if (is.factor(hotel_data[[var]])) {
    # For factors, degrees of freedom is the number of levels minus 1
    return(length(unique(hotel_data[[var]])) - 1)
  } else {
    # For continuous variables, degrees of freedom is 1
    return(1)
  }
})

# Print the degrees of freedom to check
print(df_values)

```


#logistic regression
```{r}
# Install necessary packages for model evaluation

library(caret)
library(pROC)

#hotel_data <- read.csv("../../Dataset/INNHotelsGroup_min.csv")
  
# Convert booking_status to numeric (0 for Not Canceled, 1 for Canceled)
#hotel_data$booking_status <- ifelse(hotel_data$booking_status == "Not_Canceled", 0, 1)

# Assuming the logistic regression model is already fitted
# Fit Logistic Regression model (if not already done)
log_model2 <- glm(booking_status_binary ~ lead_time + no_of_special_requests + avg_price_per_room + 
                 market_segment_type + no_of_week_nights + no_of_weekend_nights + arrival_month, 
                 data = hotel_data, family = binomial)

# Make predictions on the data (for simplicity, using the same dataset, ideally should be test data)
pred_probs <- predict(log_model2, type = "response")  # Get predicted probabilities

# Convert predicted probabilities to class labels (using 0.5 threshold)
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion Matrix
conf_matrix <- confusionMatrix(factor(pred_class), factor(hotel_data$booking_status_binary))

# Extract the confusion matrix values
cm <- conf_matrix$table
accuracy <- conf_matrix$overall['Accuracy']
precision <- conf_matrix$byClass['Precision']
recall <- conf_matrix$byClass['Recall']
f1_score <- conf_matrix$byClass['F1']
specificity <- conf_matrix$byClass['Specificity']

# Print confusion matrix with additional metrics
cat("\nConfusion Matrix and Statistics\n")
cat("\n           Reference\n")
cat("Prediction   0   1\n")
cat("           0", cm[1,1], cm[1,2], "\n")
cat("           1", cm[2,1], cm[2,2], "\n")
cat("\nAccuracy:", round(accuracy, 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:", round(recall, 4), "\n")
cat("F1-Score:", round(f1_score, 4), "\n")

# Calculate ROC-AUC
roc_curve <- roc(hotel_data$booking_status_binary, pred_probs)

# Print AUC and plot ROC curve
auc_value <- auc(roc_curve)
cat("\nAUC:", round(auc_value, 4), "\n")

# Plot ROC curve
plot(roc_curve, main = "ROC Curve for Booking Cancellation Prediction")


```

##Random forest
```{r}

library(randomForest)
library(caret)
library(pROC)

hotel_data$booking_status_binary <- as.factor(hotel_data$booking_status_binary)

# Fit Random Forest model for classification (binary target)
rf_model2 <- randomForest(booking_status_binary ~ lead_time + no_of_special_requests + avg_price_per_room + 
                          market_segment_type + no_of_week_nights + no_of_weekend_nights + arrival_month, 
                          data = hotel_data, ntree = 100)

# Print the model summary to ensure it's treated as classification
print(rf_model2)

pred_class_rf <- predict(rf_model2, newdata = hotel_data)

# Confusion Matrix (Make sure both predicted and actual values have the same levels)
conf_matrix_rf <- confusionMatrix(pred_class_rf, hotel_data$booking_status_binary)

# Print confusion matrix and the calculated metrics
print(conf_matrix_rf)

# Extracting Precision, Recall, and Accuracy from the confusion matrix
precision <- conf_matrix_rf$byClass['Pos Pred Value']
recall <- conf_matrix_rf$byClass['Sensitivity']
accuracy <- conf_matrix_rf$overall['Accuracy']

cat("\nPrecision:", round(precision, 4), "\n")
cat("Recall:", round(recall, 4), "\n")
cat("Accuracy:", round(accuracy, 4), "\n")

# Predict class probabilities for the binary outcome (probabilities for each class, we need the second column for class 1)
pred_probs_rf <- predict(rf_model2, newdata = hotel_data, type = "prob")[, 2]

# Calculate ROC-AUC for Random Forest (use the second column for class 1 probabilities)
roc_curve_rf <- roc(hotel_data$booking_status_binary, pred_probs_rf)

# Print AUC value
auc_value_rf <- auc(roc_curve_rf)
cat("\nAUC:", round(auc_value_rf, 4), "\n")

# Plot the ROC curve
plot(roc_curve_rf, main = "ROC Curve for Random Forest Model")

conf_matrix_df <- as.data.frame(as.table(conf_matrix_rf))
colnames(conf_matrix_df) <- c("Actual", "Predicted", "Freq")  # Rename columns for clarity

# Plot confusion matrix as heatmap using ggplot2
ggplot(conf_matrix_df, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "black", size = 6) +
  scale_fill_gradient(low = "white", high = "blue") +
  labs(x = "Predicted", y = "Actual", title = "Confusion Matrix Heatmap") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

#Perform cross-validation with Random Forest using 5-fold cross-validation
```{r}
# Install and load caret package

# Install and load necessary packages

library(caret)
library(doParallel)
library(randomForest)

# Set up parallel processing (use all but 1 core)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

# Reduce number of trees for faster cross-validation
ntree_val <- 50  # Use a smaller number of trees

# Perform cross-validation with Random Forest using 5-fold cross-validation
cv_model <- train(booking_status_binary ~ lead_time + no_of_special_requests + avg_price_per_room + 
                  market_segment_type + no_of_week_nights + no_of_weekend_nights + arrival_month, 
                  data = hotel_data,
                  method = "rf",
                  trControl = trainControl(method = "cv", number = 5),  # 5-fold cross-validation
                  tuneGrid = data.frame(mtry = 3),  # You can adjust mtry for tuning
                  ntree = ntree_val)  # Set ntree to a smaller value for faster computation

# Print the results of cross-validation
print(cv_model)

# Stop the parallel cluster
stopCluster(cl)


```
```{r}
# Load necessary libraries
library(corrplot)
library(ggplot2)

# Convert booking status to numeric (if it's a factor)
hotel_data$booking_status_binary <- as.numeric(hotel_data$booking_status_binary)

# Convert categorical variables (market_segment_type and arrival_month) to numeric
hotel_data$market_segment_type <- as.factor(hotel_data$market_segment_type)
hotel_data$arrival_month <- as.factor(hotel_data$arrival_month)

# Convert these factors to numeric codes
hotel_data$market_segment_type_num <- as.numeric(hotel_data$market_segment_type)
hotel_data$arrival_month_num <- as.numeric(hotel_data$arrival_month)

# Subset the relevant columns for correlation (including booking_status_binary)
corr_data <- hotel_data[, c("booking_status_binary", "lead_time", "no_of_special_requests", 
                            "avg_price_per_room", "market_segment_type_num", "no_of_week_nights", 
                            "no_of_weekend_nights", "arrival_month_num")]

# Calculate the correlation matrix
cor_matrix <- cor(corr_data)

# Print the correlation matrix
print(cor_matrix)

# Plot the correlation matrix using corrplot
corrplot(cor_matrix, method = "circle", type = "lower", tl.col = "black", tl.srt = 45)

```