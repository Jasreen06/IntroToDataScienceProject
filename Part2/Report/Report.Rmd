---
title: 'DATS6101 Project 2: Exploring Hotel Booking Cancellations'
author: "Group 6 : Jasreen Kaur Mehta, Pranav Dhawan, Tycho Gormley"
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r init, include=FALSE}
#Import required libraries
library(ezids)
library(ggplot2)
library(dplyr)
library(caret)
library(tidyverse)
library(pROC)
library(corrplot)

library(randomForest)
library(rpart)
library(glmnet)

#Setup knitter options
knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3)
```

# **Part 1 Recap**
In our Part 1, we analyzed a hotel booking dataset from the INN Hotels Group to understand the factors influencing booking cancellations.\
The dataset contained over 36,000 records with detailed information about bookings, including customer attributes, booking characteristics, and cancellation status.\

```{r import_dataset}
hotel_data <- read.csv("../../Dataset/INNHotelsGroup_min.csv")
``` 

```{r data_structure}
str(hotel_data)
```

```{r bar_plot1}
print(ggplot(hotel_data, aes(x = booking_status)) +
  geom_bar(fill = "lightblue") +
  labs(title = "Booking Status Distribution", x = "Booking Status", y = "Count"))
```

The dataset contains 36,275 bookings, with 24,390 classified as “Not Canceled” and 11,885 as “Canceled”.

## **Key Statistical Findings**

**1. Special Requests and Cancellations:** \
Bookings with special requests had a significantly lower cancellation rate (20.2%) compared to those without (43.2%).\ 
Chi-square test revealed a statistically significant association between special requests and booking status.\

**2. Previous Cancellation History:**\
Surprisingly, guests with previous cancellations had a much lower current cancellation rate (4.73%) compared to those without (33.03%).\
This suggests that past cancellation history might not be a straightforward predictor of future booking behavior.\

**3. Factors Influencing Cancellations:**\
**3.1 Lead Time:**\

1. Average lead time for canceled bookings: 139.2 days\
2. Average lead time for non-canceled bookings: 58.9 days\
3. Longer lead times strongly correlated with higher cancellation probability\

**3.2 Room Price:**\

1. Canceled bookings had a higher average room price\
2. Price difference: Approximately 10.7 units higher for canceled bookings\

**4. Seasonal Variations:**\
The correlation between factors and cancellations varied across seasons:\

**4.1 Fall:**\
Strongest lead time correlation (0.54).\

**4.2 Summer:**\
Special requests most negatively correlated with cancellations (-0.30).\

**4.3 Spring:** \
Unique pattern with special requests having a strong negative correlation (-0.36).\

**4.4 Winter:** \
Slightly different dynamics with weaker correlations\

```{r correlation, fig.width=15, fig.height=10}
hotel_data$booking_status_binary <- ifelse(hotel_data$booking_status == "Canceled", 1, 0)

remove_zero_variance <- function(df) {
  df[, sapply(df, function(col) sd(col, na.rm = TRUE) != 0)]
}

data_filtered <- remove_zero_variance(select_if(hotel_data, is.numeric))

cor_data <- cor(data_filtered, use = "complete.obs")

corrplot(cor_data, method = "color", addCoef.col = "black", 
         title = "Correlation Matrix Recap", number.cex = 1, 
         tl.cex = 0.8, mar = c(1, 1, 2, 1))
```
Lead time strongly predicts cancellations, with longer lead times increasing likelihood (0.44). More special requests (-0.25) and repeated guest status (-0.11) reduce cancellations, reflecting customer commitment and loyalty. Price per room has a weak positive correlation (0.14) with cancellations. Factors like travel party size and stay length show minimal impact on cancellation likelihood.\

## **Preliminary Conclusions:**\

**1.** Lead time emerged as the most critical factor in predicting booking cancellations.\
**2.** Special requests significantly reduce the likelihood of cancellations.\
**3.** Booking behavior varies considerably across different seasons.\
**4.** Higher-priced rooms show a slight tendency towards more cancellations.\

# **SMART Questions:** \

## **2. Can we predict the likelihood of booking cancellation based on the lead time?**\

```{r}
set.seed(123)
train_index <- createDataPartition(hotel_data$booking_status_binary, p = 0.7, list = FALSE)
train_data <- hotel_data[train_index, ]
test_data <- hotel_data[-train_index, ]
```

```{r}
logistic_model <- glm(
  booking_status_binary ~ lead_time,
  data = train_data, 
  family = binomial()
)

summary(logistic_model)
```

```{r}
test_predictions <- predict(logistic_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(test_predictions > 0.5, 1, 0)
```

```{r}
confusion_matrix <- table(Actual = test_data$booking_status_binary, 
                          Predicted = predicted_classes)
print("Confusion Matrix:")
print(confusion_matrix)
```

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2,2] / sum(confusion_matrix[,2])
recall <- confusion_matrix[2,2] / sum(confusion_matrix[2,])
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("\nModel Performance Metrics:\n")
cat("Accuracy:", round(accuracy, 4), "\n")
cat("Precision:", round(precision, 4), "\n")
cat("Recall:", round(recall, 4), "\n")
cat("F1 Score:", round(f1_score, 4), "\n")
```
**1. Accuracy:** 0.754, meaning the model correctly classifies 75.4% of the bookings.\
**2. Precision:** 0.723, indicating that 72.3% of the predictions of canceled bookings are correct.\
**3. Recall:** 0.415, meaning the model correctly identifies 41.5% of the actual canceled bookings.\
**4. F1-Score:** 0.527, which is the harmonic mean of precision and recall, providing a balanced evaluation of the model's performance.\

```{r}
roc_curve <- roc(test_data$booking_status_binary, test_predictions)
plot(roc_curve, main = "ROC Curve for Booking Cancellation Prediction")
```

The plot indicates that as the specificity (the ability to correctly identify non-canceled bookings) increases, the sensitivity (the ability to correctly identify canceled bookings) also increases. This suggests that the model has good discriminative power in predicting booking cancellations.\

```{r}
auc_value <- auc(roc_curve)
cat("Area Under the ROC Curve (AUC):", round(auc_value, 4), "\n")
```
Area Under the ROC Curve (AUC): 0.75, suggesting the model has good discriminative power in predicting booking cancellations.\

```{r}
ggplot(hotel_data, aes(x = lead_time, y = booking_status_binary)) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = TRUE) +
  labs(
    title = "Probability of Booking Cancellation vs Lead Time",
    x = "Lead Time (Days)",
    y = "Probability of Cancellation"
  ) +
  theme_minimal()
```

The graph shows the relationship between the lead time (in days) and the probability of booking cancellation. As the lead time increases, the probability of booking cancellation rises in a non-linear fashion, with the curve becoming more steep at higher lead times.\




## **5. Can we predict high-demand periods?**
 
```{r}
prepare_booking_data <- function(hotel_data) {
  booking_data <- hotel_data %>%
    mutate(
      high_demand = as.factor(ifelse(
        avg_price_per_room > quantile(avg_price_per_room, 0.75), 
        1, 0
      )),
      booking_month = as.factor(arrival_month),
      is_weekend = no_of_weekend_nights > 0,
      total_nights = no_of_weekend_nights + no_of_week_nights,
      is_repeated_guest = repeated_guest > 0
    )
  
  return(booking_data)
}
prepared_data <- prepare_booking_data(hotel_data)
```

```{r}
set.seed(123)
train_index <- createDataPartition(prepared_data$high_demand, p = 0.7, list = FALSE)
train_data <- prepared_data[train_index, ]
test_data <- prepared_data[-train_index, ]
```

```{r}
# Random Forest Model
rf_model <- randomForest(
  high_demand ~ lead_time + 
                no_of_adults + 
                no_of_children + 
                total_nights + 
                booking_month + 
                market_segment_type + 
                is_repeated_guest,
  data = train_data,
  ntree = 500,
  importance = TRUE
)

evaluate_model <- function(actual, predicted, model_name) {
  conf_matrix <- confusionMatrix(as.factor(predicted), as.factor(actual))
  
  results <- data.frame(
    Model = model_name,
    Accuracy = conf_matrix$overall['Accuracy'],
    Precision = conf_matrix$byClass['Precision'],
    Recall = conf_matrix$byClass['Recall'],
    F1 = conf_matrix$byClass['F1']
  )
  
  return(results)
}

rf_pred <- predict(rf_model, newdata = test_data, type = "prob")[,2]
rf_class <- ifelse(rf_pred > 0.5, 1, 0)
```

```{r}
rf_results <- evaluate_model(test_data$high_demand, rf_class, "Random Forest")
print(rf_results)
```


```{r}
rf_importance <- data.frame(
  Feature = rownames(importance(rf_model)),
  Importance = importance(rf_model)[,1]
) %>% arrange(desc(Importance))
print(head(rf_importance, 10))
```

```{r}
ggplot(head(rf_importance, 10), aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(
    title = "Top 10 Features Predicting High-Demand Periods",
    x = "Features",
    y = "Importance"
  ) +
  theme_minimal()
```

```{r}
predict_high_demand_periods <- function(model, test_data) {
  pred_probs <- predict(model, newdata = test_data, type = "prob")[,2]
  high_demand_periods <- test_data[pred_probs > 0.7, ]
  
  print("High-Demand Periods Prediction:")
  print(paste("Total High-Demand Periods:", sum(pred_probs > 0.7)))
  print("Sample of High-Demand Periods:")
  print(head(high_demand_periods))
  
  return(high_demand_periods)
}

high_demand_periods <- predict_high_demand_periods(rf_model, test_data)
```